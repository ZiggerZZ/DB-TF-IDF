{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Job1: simple wordcount on term-document tuples to compute tf\n",
    "\n",
    "### Map\n",
    "# Input: (docname, contents):\n",
    "# Output: ((docname,term), 1)\n",
    "\n",
    "### Reduce\n",
    "# Input: ((docname,term), 1)\n",
    "# Output: ((term,docname), (N,n))\n",
    "\n",
    "###########################################  mapper1.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    line = line.strip()\n",
    "    terms = line.split(\" \")\n",
    "    \n",
    "    path = os.environ['mapreduce_map_input_file'].split('/')\n",
    "    docname = path[-1]\n",
    "    \n",
    "    for term in terms:\n",
    "        term = term.strip('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''').lower()\n",
    "        print('%s\\t%s' % (term + '_' + docname, 1))\n",
    "        \n",
    "        \n",
    "###########################################  reducer1.py\n",
    "\n",
    "import sys\n",
    "\n",
    "current_pair = None\n",
    "current_count = 0\n",
    "pair = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    line = line.strip()\n",
    "    pair, count = line.split('\\t', 1)\n",
    " \n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    " \n",
    "    if current_pair == pair:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_pair:\n",
    "            # write result to STDOUT\n",
    "            print ('%s\\t%s' % (current_pair, current_count))\n",
    "        current_count = count\n",
    "        current_pair = pair\n",
    "\n",
    "if current_pair == pair:\n",
    "        print ('%s\\t%s' % (current_pair, current_count))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Job2: append document frequency d to term_doc pairs\n",
    "\n",
    "### Map\n",
    "# Input:  ((term,docname), (N,n))\n",
    "# Output: (term, (docname,N,n,1))\n",
    "\n",
    "### Reduce\n",
    "# Input: (term, (docname,N,n,1))\n",
    "# Output: ((term,docname), (N,n,d))\n",
    "\n",
    "\n",
    "\n",
    "###########################################  mapper2.py\n",
    "\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    term,rest = line.split('_')\n",
    "    docname,n = rest.split('\\t')\n",
    "    \n",
    "    try:\n",
    "        n = int(n)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    print('%s\\t%s' % (term, docname + '_' + n + '_' + 1))\n",
    "        \n",
    "        \n",
    "###########################################  reducer2.py\n",
    "\n",
    "import sys\n",
    "\n",
    "current_term = None\n",
    "doc_list = []\n",
    "n_list=[]\n",
    "current_count = 0\n",
    "term = None\n",
    "doc = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "\n",
    "    term,rest = line.split('\\t',1)\n",
    "    doc,n,count = rest.split('_', 2)\n",
    " \n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    " \n",
    "    if current_term == term:\n",
    "        doc_list.append(doc)\n",
    "        n_list.append(n)\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_term:\n",
    "            for i,document in enumerate(doc_list):\n",
    "                print ('%s\\t%s' % (current_term + '_' + document, n_list[i] + '_' + str(current_count)))\n",
    "            doc_list = []   \n",
    "            n_list = []\n",
    "            \n",
    "        current_count = count\n",
    "        current_term = term\n",
    "        doc_list.append(doc)\n",
    "        n_list.append(n)\n",
    "        \n",
    "        \n",
    "\n",
    "if current_term == term:\n",
    "    for i,document in enumerate(doc_list):\n",
    "        print ('%s\\t%s' % (current_term + '_' + document, n_list[i] + '_' + str(current_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Job3: compute tf-idfs\n",
    "\n",
    "### Map\n",
    "# Input:  ((term,docname), (N,n,d))\n",
    "# Output: ((term,docname), tfidf)\n",
    "\n",
    "### Reduce ----pass\n",
    "# Input:\n",
    "# Output: \n",
    "\n",
    "###########################################  mapper3.py\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    pair,rest = line.split('/t',1)\n",
    "    n,d = rest.split('_',1)\n",
    "    \n",
    "    try:\n",
    "        n = int(n)\n",
    "        d = int (d)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    ## to calculate these with normalizing terms we need to compute:\n",
    "    # 1. the total of words in each documents\n",
    "    # 2. the total number of documents in the corpus\n",
    "    # look into Hadoop global variables/ counters\n",
    "    \n",
    "    tf = n  \n",
    "    idf = math.log(1/(1+d))\n",
    "    tfidf = tf * idf\n",
    "    \n",
    "    \n",
    "    print('%s\\t%s' % (pair, tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minutes Jan 31st meeting:\n",
    "    - computation of Nj and D\n",
    "    - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
