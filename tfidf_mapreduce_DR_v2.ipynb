{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Job1: simple wordcount on term-document tuples to compute tf\n",
    "\n",
    "### Map\n",
    "# Input: (docname, contents):\n",
    "# Output: ((docname,term), 1)\n",
    "\n",
    "### Reduce\n",
    "# Input: ((docname,term), 1)\n",
    "# Output: ((term,docname), (N,n))\n",
    "\n",
    "###########################################  mapper1.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "### D = ?????\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    line = line.strip()\n",
    "    terms = line.split(\" \")\n",
    "       \n",
    "    path = os.environ['mapreduce_map_input_file'].split('/')\n",
    "    docname = path[-1]\n",
    "    \n",
    "    for term in terms:\n",
    "        term = term.strip('''!()-[]{};:'\"\\,<>./?@#$%^&*_~''').lower()\n",
    "        print('%s\\t%s' % (term + '_' + docname, 1))\n",
    "        \n",
    "        \n",
    "###########################################  reducer1.py\n",
    "\n",
    "import sys\n",
    "\n",
    "current_file = None\n",
    "current_term = None\n",
    "term_list = []\n",
    "current_term_count = 0\n",
    "current_doc_count = 0\n",
    "pair = None\n",
    "\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    line = line.strip()\n",
    "    pair, count = line.split('\\t', 1)\n",
    "    \n",
    "    file, term = pair.split('_', 1)\n",
    " \n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    " \n",
    "    if current_file == file:\n",
    "        current_doc_count += count\n",
    "        if current_term == term:\n",
    "            current_term_count += count\n",
    "        else:\n",
    "            term_list.append((term, current_term_count))\n",
    "            current_term = term\n",
    "            current_term_count = count\n",
    "    else:\n",
    "        if current_file:\n",
    "            # write result to STDOUT\n",
    "            for term,current_term_count in term_list:\n",
    "                print ('%s\\t%s' % (term+'_'+file, str(current_doc_count)+'_'+(str(current_term_count))))\n",
    "        current_doc_count = count\n",
    "        current_file = file\n",
    "        current_term = term\n",
    "        term_list = []   \n",
    "\n",
    "if (current_file == file and current_term == term):\n",
    "    for term,current_term_count in term_list: \n",
    "        print ('%s\\t%s' % (term+'_'+file, str(current_doc_count)+'_'+(str(current_term_count))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Job2: append document frequency d to term_doc pairs\n",
    "\n",
    "### Map\n",
    "# Input:  ((term,docname), (N,n))\n",
    "# Output: (term, (docname,N,n,1))\n",
    "\n",
    "### Reduce\n",
    "# Input: (term, (docname,N,n,1))\n",
    "# Output: ((term,docname), (N,n,d))\n",
    "\n",
    "\n",
    "\n",
    "###########################################  mapper2.py\n",
    "\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    pair,vals = line.split('\\t')\n",
    "    term,docname = pair.split('_',1)\n",
    "    N,n = vals.split('_')\n",
    "    \n",
    "    try:\n",
    "        n = int(n)\n",
    "        N = int(N)\n",
    "    except ValueError:\n",
    "        continue\n",
    "    \n",
    "    print('%s\\t%s' % (term, docname + '_'+str(N) + '_' + str(n) + '_' + str(1)))\n",
    "        \n",
    "        \n",
    "###########################################  reducer2.py\n",
    "\n",
    "import sys\n",
    "\n",
    "current_term = None\n",
    "doc_list = []\n",
    "current_count = 0\n",
    "term = None\n",
    "doc = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "\n",
    "    term,rest = line.split('\\t',1)\n",
    "    doc,N,n,count = rest.rsplit('_',3)\n",
    " \n",
    "    # convert count (currently a string) to int\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        # count was not a number, so silently\n",
    "        # ignore/discard this line\n",
    "        continue\n",
    " \n",
    "    if current_term == term:\n",
    "        doc_list.append((doc,N,n))\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_term:\n",
    "            for document,N,n in doc_list:\n",
    "                print ('%s\\t%s' % (current_term + '_' + document, str(N)+'_' + str(n) + '_' + str(current_count))\n",
    "            doc_list = []   \n",
    "            n_list = []\n",
    "            \n",
    "        current_count = count\n",
    "        current_term = term\n",
    "        doc_list.append((doc,N,n))\n",
    "        \n",
    "        \n",
    "\n",
    "if current_term == term:\n",
    "    for document,N,n in doc_list:\n",
    "        print ('%s\\t%s' % (current_term + '_' + document, str(N)+'_' + str(n) + '_' + str(current_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Job3: compute tf-idfs\n",
    "\n",
    "### Map\n",
    "# Input:  ((term,docname), (N,n,d))\n",
    "# Output: ((term,docname), tfidf)\n",
    "\n",
    "### Reduce ----pass\n",
    "# Input:((term,docname), tfidf)\n",
    "# Output: ((term,docname), tfidf)\n",
    "\n",
    "###########################################  mapper3.py\n",
    "\n",
    "import sys\n",
    "import math\n",
    "\n",
    "for line in sys.stdin:\n",
    "    \n",
    "    pair,vals = line.split('\\t',1)\n",
    "    N,n,d = rest.split('_',2)\n",
    "    \n",
    "    try:\n",
    "        N = int(N)\n",
    "        n = int(n)\n",
    "        d = int (d)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    ## to calculate these with normalizing terms we need to compute:\n",
    " \n",
    "    \n",
    "    tf = n/N  \n",
    "    idf = math.log(10000/(1+d))\n",
    "    tfidf = tf * idf\n",
    "    \n",
    "    print('%s\\t%s' % (pair, tfidf))\n",
    "    \n",
    "    \n",
    "###########################################  reducer3.py\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "for line in sys.stdin:\n",
    "    print (line)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minutes Jan 31st meeting:\n",
    "    - computation of Nj and D\n",
    "    - "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
